{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "import io\n",
    "import random\n",
    "import warnings\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    label  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  neptune  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the Data\n",
    "train_df = pd.read_csv(\"NSL_train.csv\")\n",
    "test_df  = pd.read_csv(\"NSL_test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42,\n",
       " Index(['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
       "        'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
       "        'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
       "        'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
       "        'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "        'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "        'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "        'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "        'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "        'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "        'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "        'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "        'dst_host_srv_rerror_rate', 'label'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df.columns), train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Training set:\n",
      "23\n",
      "normal             67343\n",
      "neptune            41214\n",
      "satan               3633\n",
      "ipsweep             3599\n",
      "portsweep           2931\n",
      "smurf               2646\n",
      "nmap                1493\n",
      "back                 956\n",
      "teardrop             892\n",
      "warezclient          890\n",
      "pod                  201\n",
      "guess_passwd          53\n",
      "buffer_overflow       30\n",
      "warezmaster           20\n",
      "land                  18\n",
      "imap                  11\n",
      "rootkit               10\n",
      "loadmodule             9\n",
      "ftp_write              8\n",
      "multihop               7\n",
      "phf                    4\n",
      "perl                   3\n",
      "spy                    2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Training set:')\n",
    "print(train_df['label'].nunique())\n",
    "print(train_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution Test set:\n",
      "label\n",
      "normal             9711\n",
      "neptune            4657\n",
      "guess_passwd       1231\n",
      "mscan               996\n",
      "warezmaster         944\n",
      "apache2             737\n",
      "satan               735\n",
      "processtable        685\n",
      "smurf               665\n",
      "back                359\n",
      "snmpguess           331\n",
      "saint               319\n",
      "mailbomb            293\n",
      "snmpgetattack       178\n",
      "portsweep           157\n",
      "ipsweep             141\n",
      "httptunnel          133\n",
      "nmap                 73\n",
      "pod                  41\n",
      "buffer_overflow      20\n",
      "multihop             18\n",
      "named                17\n",
      "ps                   15\n",
      "sendmail             14\n",
      "rootkit              13\n",
      "xterm                13\n",
      "teardrop             12\n",
      "xlock                 9\n",
      "land                  7\n",
      "xsnoop                4\n",
      "ftp_write             3\n",
      "worm                  2\n",
      "loadmodule            2\n",
      "perl                  2\n",
      "sqlattack             2\n",
      "udpstorm              2\n",
      "phf                   2\n",
      "imap                  1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Label distribution Test set:')\n",
    "print(test_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Column 'protocol_type' has 3 categories\n",
      "Column 'service' has 70 categories\n",
      "Column 'flag' has 11 categories\n",
      "Column 'label' has 23 categories\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Training set:')\n",
    "categorical_columns = train_df.select_dtypes(['object']).columns.tolist()\n",
    "for col_name in categorical_columns:\n",
    "    unique_cat = len(train_df[col_name].unique())\n",
    "    print(f\"Column '{col_name}' has {unique_cat} categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type', 'service', 'flag']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns.remove('label')\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['protocol_type', 'service', 'flag']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "combined_data = pd.concat([train_df, test_df], axis=0)\n",
    "# List of categorical columns\n",
    "print(categorical_columns) \n",
    "\n",
    "\n",
    "label_encoders = {} \n",
    "\n",
    "for column in categorical_columns:\n",
    "    lb = LabelEncoder()\n",
    "    lb.fit(combined_data[column])\n",
    "    label_encoders[column] = lb\n",
    "    combined_data[column] = lb.transform(combined_data[column])\n",
    "\n",
    "train_data = combined_data[:len(train_df)]\n",
    "test_data = combined_data[len(train_df):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labels Processing : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = { 'normal' : 0, 'neptune' : 1 ,'back': 1, 'land': 1, 'pod': 1, 'smurf': 1, 'teardrop': 1,'mailbomb': 1, 'apache2': 1, 'processtable': 1, 'udpstorm': 1, 'worm': 1,\n",
    "                           'ipsweep' : 2,'nmap' : 2,'portsweep' : 2,'satan' : 2,'mscan' : 2,'saint' : 2\n",
    "                           ,'ftp_write': 3,'guess_passwd': 3,'imap': 3,'multihop': 3,'phf': 3,'spy': 3,'warezclient': 3,'warezmaster': 3,'sendmail': 3,'named': 3,'snmpgetattack': 3,'snmpguess': 3,'xlock': 3,'xsnoop': 3,'httptunnel': 3,\n",
    "                           'buffer_overflow': 4,'loadmodule': 4,'perl': 4,'rootkit': 4,'ps': 4,'sqlattack': 4,'xterm': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_classes = {\"DoS\" : [0,1], \"Probe\" : [0,2], \"R2L\" : [0,3], \"U2R\" : [0,4]}\n",
    "train_data['label'] = train_data['label'].replace(label_categories)\n",
    "test_data['label'] = test_data['label'].replace(label_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_dfs = {\n",
    "    \"DoS\" : (train_data[train_data['label'].isin(label_classes['DoS'])], test_data[test_data['label'].isin(label_classes['DoS'])]),\n",
    "    \"Probe\" : (train_data[train_data['label'].isin(label_classes['Probe'])], test_data[test_data['label'].isin(label_classes['Probe'])]),\n",
    "    \"R2L\" : (train_data[train_data['label'].isin(label_classes['R2L'])], test_data[test_data['label'].isin(label_classes['R2L'])]),\n",
    "    \"U2R\" : (train_data[train_data['label'].isin(label_classes['U2R'])], test_data[test_data['label'].isin(label_classes['U2R'])]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train, Test from Categorical labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_train_test_data(categorical_dfs, category : str) : \n",
    "    df = categorical_dfs[category][0]\n",
    "    X_train = df.drop('label',axis=1)\n",
    "    Y_train = df.label\n",
    "    \n",
    "    df_test = categorical_dfs[category][1]\n",
    "    X_test = df_test.drop('label',axis=1)\n",
    "    Y_test = df_test.label\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data using StandardScaler to fit the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def train_test_transformed(categorical_dfs, category):\n",
    "\n",
    "    X_train, Y_train, X_test, Y_test = return_train_test_data(categorical_dfs, category)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
    "    X_test = scaler_test.transform(X_test)\n",
    "\n",
    "    return X_train, Y_train.astype(int), X_test, Y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We are using three classifiers here and we will select the best features from the three classifiers.\n",
    "classifiers = [SVC(kernel='linear', C=1.0, random_state=0), RandomForestClassifier(n_estimators=10,n_jobs=2), KNeighborsClassifier()]\n",
    "rfe = RFE(estimator=classifiers[1], n_features_to_select=13, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = train_test_transformed(categorical_dfs, \"DoS\")\n",
    "#Fit the feature selector on the training data\n",
    "rfe.fit(X_train, Y_train.astype(int))\n",
    "# Transform the training data to get the selected features\n",
    "X_rfe = rfe.transform(X_train)\n",
    "\n",
    "#Get the list of columns from the categorical_dfs : \n",
    "column_Names =list(categorical_dfs[\"DoS\"][0])\n",
    "\n",
    "#Get the list of selected columns\n",
    "column_indexes =[i for i, x in enumerate(rfe.support_) if x]\n",
    "selected_column_names = [column_Names[i] for i in column_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113270, 41), (113270, 13))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_rfe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the data on feature selector reveals only 13 columns are used to make the prediction from the 41 present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['protocol_type',\n",
       " 'service',\n",
       " 'flag',\n",
       " 'src_bytes',\n",
       " 'dst_bytes',\n",
       " 'wrong_fragment',\n",
       " 'num_compromised',\n",
       " 'count',\n",
       " 'srv_count',\n",
       " 'same_srv_rate',\n",
       " 'diff_srv_rate',\n",
       " 'dst_host_same_srv_rate',\n",
       " 'dst_host_srv_serror_rate']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def run_training(categorical_dfs, category : str , classifier : int ) : \n",
    "    \n",
    "    X_train, Y_train, X_test, Y_test = train_test_transformed(categorical_dfs, category)\n",
    "\n",
    "    rfe.fit(X_train, Y_train.astype(int))\n",
    "    # Transform the training, test data to get the selected features\n",
    "    X_train_rfe = rfe.transform(X_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    model = classifiers[classifier]\n",
    "    model.fit(X_train_rfe, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test_rfe)\n",
    "    \n",
    "    print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))\n",
    "    print(\"Precision:\",metrics.precision_score(Y_test, Y_pred, average='weighted'))\n",
    "    print(\"Recall:\",metrics.recall_score(Y_test, Y_pred, average='weighted'))\n",
    "    print(\"F1:\",metrics.f1_score(Y_test, Y_pred, average='weighted'))\n",
    "\n",
    "    return pd.crosstab(Y_test, Y_pred, rownames=['Actual attacks'], colnames=['Predicted attacks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8716440510162483\n",
      "Precision: 0.8758730627421681\n",
      "Recall: 0.8716440510162483\n",
      "F1: 0.8699758230838476\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9159   552\n",
      "1                  1652  5808\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have modularized the codes, we can run this experiment for across the list of models vs category of attacks \n",
    "Model Catalog : \n",
    "\n",
    "0 = SVC \n",
    "\n",
    "1 = RandomForestClassifier\n",
    "\n",
    "2 = KNN\n",
    "\n",
    "Attack Categories : \n",
    "\n",
    "[ \"DoS\" , \"Probe\" , \"R2L\" , \"U2R\" ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7702445220704985\n",
      "Precision: 0.6641921603505512\n",
      "Recall: 0.7702445220704985\n",
      "F1: 0.6719380564354002\n",
      "Predicted attacks     0   3\n",
      "Actual attacks             \n",
      "0                  9695  16\n",
      "3                  2878   7\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878503132212331\n",
      "Precision: 0.8775712514915698\n",
      "Recall: 0.878503132212331\n",
      "F1: 0.8631641784393244\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9544   167\n",
      "2                  1307  1114\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941705870321129\n",
      "Precision: 0.9932214782492162\n",
      "Recall: 0.9941705870321129\n",
      "F1: 0.9923872564552023\n",
      "Predicted attacks     0   4\n",
      "Actual attacks             \n",
      "0                  9708   3\n",
      "4                    54  13\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 0)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8634325315939666\n",
      "Precision: 0.8869095419811458\n",
      "Recall: 0.8634325315939666\n",
      "F1: 0.8584623391126935\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9654    57\n",
      "1                  2288  5172\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8778437190900099\n",
      "Precision: 0.8717842472879904\n",
      "Recall: 0.8778437190900099\n",
      "F1: 0.8668931685374486\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9411   300\n",
      "2                  1182  1239\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7709590346141633\n",
      "Precision: 0.7089314900062045\n",
      "Recall: 0.7709590346141633\n",
      "F1: 0.6713993992034822\n",
      "Predicted attacks     0  3\n",
      "Actual attacks            \n",
      "0                  9710  1\n",
      "3                  2884  1\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941705870321129\n",
      "Precision: 0.9942046038768273\n",
      "Recall: 0.9941705870321129\n",
      "F1: 0.9920214762638171\n",
      "Predicted attacks     0   4\n",
      "Actual attacks             \n",
      "0                  9711   0\n",
      "4                    57  10\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 1)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9184089453147749\n",
      "Precision: 0.9268460924267232\n",
      "Recall: 0.9184089453147749\n",
      "F1: 0.91709588218927\n",
      "Predicted attacks     0     1\n",
      "Actual attacks               \n",
      "0                  9653    58\n",
      "1                  1343  6117\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"DoS\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9135344543356413\n",
      "Precision: 0.912193267053767\n",
      "Recall: 0.9135344543356413\n",
      "F1: 0.9079833689634926\n",
      "Predicted attacks     0     2\n",
      "Actual attacks               \n",
      "0                  9524   187\n",
      "2                   862  1559\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"Probe\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7705620832010162\n",
      "Precision: 0.6568729894146405\n",
      "Recall: 0.7705620832010162\n",
      "F1: 0.6715021169635647\n",
      "Predicted attacks     0  3\n",
      "Actual attacks            \n",
      "0                  9703  8\n",
      "3                  2882  3\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = run_training(categorical_dfs, \"R2L\", 2)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9945796686438945\n",
      "Precision: 0.993766025422206\n",
      "Recall: 0.9945796686438945\n",
      "F1: 0.9932156249855\n",
      "Predicted attacks     0   4\n",
      "Actual attacks             \n",
      "0                  9707   4\n",
      "4                    49  18\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix= run_training(categorical_dfs, \"U2R\", 2)\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
